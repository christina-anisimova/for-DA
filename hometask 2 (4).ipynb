import requests
from tqdm.auto import tqdm
import pandas as pd

sber = '3529'
page = 1
num_per_page = 100
moscow = 1
url = f'https://api.hh.ru/vacancies?employer_id={sber}&page={page}&per_page={num_per_page}'

url = f'https://api.hh.ru/vacancies'
params = {
    'employer_id':sber,
    'page':page,
    'per_page':num_per_page,
    'area':moscow,
}
res = requests.get(url, params=params)

res.json()

res = requests.get(url)

print(res)

vacancies = res.json()
num_pages = vacancies.get('pages')
num_pages

vacancies.keys()

vacancies.get('items')[0]

v = vacancies.get('items')

vacancies.keys()

vacancies = res.json()
num_pages = vacancies.get('pages')
vacancy_ids = [el.get('id') for el in vacancies.get('items')]


vacancies.keys()

vnum  = vacancies.get('pages')

num_per_page

all_vacancy_ids= []
for i in tqdm(range(vnum)):
    url = f'https://api.hh.ru/vacancies?employer_id={sber}&page={i}&per_page={num_per_page}'
    res = requests.get(url)
    vacancies = res.json()
    vacancy_ids = [el.get('id') for el in vacancies.get('items')]
    all_vacancy_ids.extend(vacancy_ids)

vacancies

len(all_vacancy_ids)
# https://api.hh.ru/vacancies/66634517

all_vacancy_ids
vacs = []
for vac_id in tqdm(all_vacancy_ids):
    url = f'https://api.hh.ru/vacancies/{vac_id}'
    res = requests.get(url)
    vacs.append(res.json())

res = requests.get(url)

res.json().keys()

[x.get('name') for x in  res.json().get('key_skills')]

[x.get('name') for x in vacs]

res.json().get('name')

'Аналитик данных'

res.json().get('key_skills')

[{'name':'SQL'},{'name':'Python'},{'name':'Git'}]

[x.get('name') for x in [{'name':'SQL'},{'name':'Python'},{'name':'Git'}]]
vacs[0]

df = pd.json_normalize(vacs)

df.head()
# df.name.str.contains('аналит')

#собираем в список все вакансии аналитиков с применением питон

list_of_skills = df[df.name.str.contains('аналит')
& df.description.str.lower().str.contains('python')]['key_skills'].apply(lambda x:[s.get('name') for s in x]).tolist()
all_skills = []
for x in list_of_skills:
    all_skills.extend(x)
from collections import Counter
c = Counter(all_skills)

#вывести топ3 востребованных скила
c.most_common(5)

#перевести даты
df.created_at = pd.to_datetime(df.created_at)
df.created_at.dtype
df.created_at = df.created_at.dt.date

#построить график публикации вакансий по датам
from pylab import rcParams
rcParams['figure.figsize'] = 9,9
df.groupby('created_at')['id'].count().plot(kind='barh');

#найти интересные вакансии с применением питон\sql
df[df.name.str.lower().str.contains('junior|аналитик') & df.description.str.lower().str.contains('python|sql')]

#Определите по полю skills какие навыки больше всего востребованы для этих вакансий
#формируем список с интересными вакансиями
list_of_interests = df[df.name.str.contains('junior|аналитик')
& df.description.str.lower().str.contains('python|sql')]['key_skills'].apply(lambda p:[d.get('name') for d in p]).tolist()

#записываем все интересные вакансии с заданными параметрами в список
all_interests = []
for p in list_of_interests:
    all_interests.extend(p)
from collections import Counter
i = Counter(all_interests)


#вывести топ5 востребованных скила
i.most_common(5)
